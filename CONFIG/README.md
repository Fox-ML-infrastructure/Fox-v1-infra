# Configuration System

This directory contains all configuration files for the FoxML Core pipeline.

## Directory Structure

The configuration system uses a modular structure to prevent config "crossing" between pipeline components:

```
CONFIG/
â”œâ”€â”€ experiments/              # Experiment-level configs (what are we running?)
â”‚   â”œâ”€â”€ e2e_ranking_test.yaml
â”‚   â””â”€â”€ fwd_ret_60m_test.yaml
â”œâ”€â”€ feature_selection/        # Feature selection module configs
â”‚   â””â”€â”€ multi_model.yaml
â”œâ”€â”€ target_ranking/           # Target ranking module configs
â”‚   â””â”€â”€ multi_model.yaml
â”œâ”€â”€ training_config/          # Training pipeline configs (SST: Single Source of Truth)
â”‚   â”œâ”€â”€ intelligent_training_config.yaml  # Main intelligent trainer config
â”‚   â”œâ”€â”€ decision_policies.yaml            # Decision policy thresholds (NEW)
â”‚   â”œâ”€â”€ stability_config.yaml             # Stability analysis thresholds (NEW)
â”‚   â”œâ”€â”€ safety_config.yaml                # Safety & temporal configs
â”‚   â”œâ”€â”€ system_config.yaml                # System resources
â”‚   â”œâ”€â”€ pipeline_config.yaml              # Pipeline behavior
â”‚   â”œâ”€â”€ preprocessing_config.yaml         # Data preprocessing
â”‚   â”œâ”€â”€ optimizer_config.yaml             # Optimizer settings
â”‚   â”œâ”€â”€ gpu_config.yaml                   # GPU settings
â”‚   â”œâ”€â”€ memory_config.yaml                # Memory management
â”‚   â”œâ”€â”€ threading_config.yaml             # Threading policy
â”‚   â”œâ”€â”€ routing_config.yaml               # Target routing
â”‚   â”œâ”€â”€ callbacks_config.yaml             # Training callbacks
â”‚   â”œâ”€â”€ family_config.yaml                # Model family configs
â”‚   â”œâ”€â”€ sequential_config.yaml            # Sequential training
â”‚   â””â”€â”€ first_batch_specs.yaml            # First batch specs
â”œâ”€â”€ model_config/             # Model-specific hyperparameters
â”‚   â”œâ”€â”€ lightgbm.yaml
â”‚   â”œâ”€â”€ xgboost.yaml
â”‚   â”œâ”€â”€ neural_network.yaml
â”‚   â””â”€â”€ ... (all model families)
â”œâ”€â”€ routing/                  # Routing configs
â”‚   â””â”€â”€ default.yaml
â”œâ”€â”€ logging_config.yaml       # Structured logging configuration
â”œâ”€â”€ feature_registry.yaml     # Feature registry (allowed/excluded)
â”œâ”€â”€ excluded_features.yaml    # Always-excluded features
â”œâ”€â”€ defaults.yaml             # Global defaults (SST)
â””â”€â”€ config_loader.py          # Configuration loader
```

## Config Files Status

### âœ… Active Config Files
All files in `training_config/`, `model_config/`, `feature_selection/`, `target_ranking/`, and `experiments/` are actively used.

### âš ï¸ Potentially Unused Files (Verify Before Removing)
- `comprehensive_feature_ranking.yaml` - May be legacy
- `fast_target_ranking.yaml` - May be legacy
- `feature_selection_config.yaml` - May be legacy
- `target_configs.yaml` - Referenced in code, verify usage
- `feature_target_schema.yaml` - Referenced in code, verify usage
- `feature_groups.yaml` - Verify usage
- `training/models.yaml` - May be superseded by `model_config/`

### ğŸ—‘ï¸ Deprecated Files (Safe to Remove)
- `multi_model_feature_selection.yaml.deprecated` - Explicitly deprecated, moved to `feature_selection/multi_model.yaml`

## Quick Start

### Using Experiment Configs (Recommended)

Create an experiment config in `CONFIG/experiments/`:

```yaml
experiment:
  name: my_experiment
  description: "Test run"

data:
  data_dir: data/data_labeled/interval=5m
  symbols: [AAPL, MSFT]
  interval: 5m
  max_samples_per_symbol: 3000

targets:
  primary: fwd_ret_60m

feature_selection:
  top_n: 30
  model_families: [lightgbm, xgboost]

training:
  model_families: [lightgbm, xgboost]
  cv_folds: 5
```

Then run:

```bash
python TRAINING/train.py --experiment-config my_experiment
```

### Legacy Usage (Still Supported)

You can still use individual config files:

```bash
python TRAINING/train.py \
    --data-dir data/data_labeled/interval=5m \
    --symbols AAPL MSFT \
    --targets fwd_ret_60m
```

## Migration Guide

### Feature Selection Config

**Old location:** `CONFIG/multi_model_feature_selection.yaml`  
**New location:** `CONFIG/feature_selection/multi_model.yaml`

The config loader automatically checks the new location first, then falls back to legacy. You'll see a deprecation warning if using the old location.

### Target Ranking Config

**Old location:** Uses feature selection config  
**New location:** `CONFIG/target_ranking/multi_model.yaml`

### Training Config

**Old location:** Various files in `CONFIG/training_config/`  
**New location:** `CONFIG/training/models.yaml` (for model families)

Training still uses `CONFIG/training_config/` for pipeline, GPU, memory, etc. settings.

## Documentation

- **Configuration Reference:** See `DOCS/02_reference/configuration/`
- **Experiment Configs:** See `CONFIG/experiments/README.md`
- **Feature Selection:** See `CONFIG/feature_selection/README.md`

## Backward Compatibility

All legacy config locations are still supported with deprecation warnings. The system will:
1. Check new location first
2. Fall back to legacy location if new doesn't exist
3. Show deprecation warning when using legacy location

This ensures existing code continues to work while encouraging migration to the new structure.
